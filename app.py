import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from io import BytesIO

st.title("Scraping des Ã©lus des cantons alsaciens")

# URL cible (Ã  modifier selon la page que tu veux scraper)
url = st.text_input("Entrez l'URL de la page Ã  scraper :", "https://exemple.com/cantons")

if st.button("Lancer le scraping"):
    try:
        # RÃ©cupÃ©ration du contenu HTML
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # Extraction du texte brut
        text = soup.get_text(separator="\n")

        # DÃ©couper par canton
        lines = [l.strip() for l in text.split("\n") if l.strip() != ""]

        data = []
        current_canton = None
        current_names = []

        # Mots Ã  ignorer
        blacklist = [
            "Une question ?", "Conseiller d'Alsace", "ConseillÃ¨re d'Alsace",
            "Twitter", "Facebook", "En savoir plus sur ce canton"
        ]

        for line in lines:
            if line.startswith("Canton de"):
                # Sauvegarde du canton prÃ©cÃ©dent
                if current_canton and current_names:
                    row = {"Canton": current_canton}
                    for i, name in enumerate(current_names, start=1):
                        row[f"Ã‰lu {i}"] = name
                    data.append(row)
                current_canton = line
                current_names = []
            elif line not in blacklist and current_canton:
                # Cas oÃ¹ c'est un Ã©lu (on suppose que ce nâ€™est pas dans blacklist)
                # Petit filtre : on ignore les phrases trop longues (>6 mots)
                if len(line.split()) <= 5:
                    current_names.append(line)

        # Sauvegarde du dernier canton
        if current_canton and current_names:
            row = {"Canton": current_canton}
            for i, name in enumerate(current_names, start=1):
                row[f"Ã‰lu {i}"] = name
            data.append(row)

        # Affichage dans un tableau
        df = pd.DataFrame(data)
        st.dataframe(df)

        # Export en Excel
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="Ã‰lus")
        st.download_button(
            label="ğŸ“¥ TÃ©lÃ©charger en Excel",
            data=output.getvalue(),
            file_name="elus_cantons.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.error(f"Erreur lors du scraping : {e}")
